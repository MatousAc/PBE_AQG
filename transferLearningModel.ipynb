{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with Transformers and PyTorch on the potsawee T5 model\n",
    "In this notebook I demonstrate how to perform transfer learning on an existing T5 model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again I make sure that pyTorch is installed and I import generally useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally useful libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mashu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "c:\\Users\\mashu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global setting variables (eventually should go into a .json) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = ' <sep> '\n",
    "PBEDataSource = 'singlePointQuestions.csv'\n",
    "bibleDataSource = 'nkjv.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "For the training to occur, I need to create a dataset in my code that includes all the inputs and outputs of my model. These come from two different sources. Inputs are technically the verses in [`nkjv.csv`](nkjv.csv) and the outputs are in my [`singlePointQuestions.csv`](singlePointQuestions.csv). Below I define functions that put these two sources together into a pandas data frame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I load the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>ChapterNumber</th>\n",
       "      <th>VerseNumber</th>\n",
       "      <th>Verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heavens and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The earth was without form, and void; and dark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Then God said, \"Let there be light\"; and there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God saw the light, that it was good; and G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>God called the light Day, and the darkness He ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Book  ChapterNumber  VerseNumber  \\\n",
       "0  Genesis              1            1   \n",
       "1  Genesis              1            2   \n",
       "2  Genesis              1            3   \n",
       "3  Genesis              1            4   \n",
       "4  Genesis              1            5   \n",
       "\n",
       "                                               Verse  \n",
       "0  In the beginning God created the heavens and t...  \n",
       "1  The earth was without form, and void; and dark...  \n",
       "2  Then God said, \"Let there be light\"; and there...  \n",
       "3  And God saw the light, that it was good; and G...  \n",
       "4  God called the light Day, and the darkness He ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nkjv = pd.read_csv(bibleDataSource)\n",
    "nkjv.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I define a function that will get any span of verses specified by parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And He said to him, \"Most assuredly, I say to you, hereafter you shall see heaven open, and the angels of God ascending and descending upon the Son of Man.\" On the third day there was a wedding in Cana of Galilee, and the mother of Jesus was there. Now both Jesus and His disciples were invited to the wedding. \n",
      "In the beginning God created the heavens and the earth. The earth was without form, and void; and darkness was on the face of the deep. And the Spirit of God was hovering over the face of the waters. Then God said, \"Let there be light\"; and there was light. \n",
      "But fornication and all uncleanness or covetousness, let it not even be named among you, as is fitting for saints; \n"
     ]
    }
   ],
   "source": [
    "# note that this function does not support verses across multiple books\n",
    "def getText(Book, StartChapter, StartVerse, EndChapter = None, EndVerse = None):\n",
    "  # default to start positions\n",
    "  EndChapter = EndChapter if EndChapter else StartChapter\n",
    "  EndVerse = EndVerse if EndVerse else StartVerse\n",
    "\n",
    "  text = \"\"\n",
    "  BookDf = nkjv[nkjv[\"Book\"] == Book]\n",
    "  for index, row in BookDf.iterrows():\n",
    "    chapter = row['ChapterNumber']\n",
    "    verse = row['VerseNumber']\n",
    "    if (chapter == StartChapter and verse >= StartVerse) or (chapter > StartChapter):\n",
    "      if chapter == EndChapter and verse > EndVerse:\n",
    "        break\n",
    "      text += row['Verse'] + \" \"\n",
    "  return text\n",
    "  \n",
    "\n",
    "print(getText(\"John\", 1, 51, 2, 2))   # John 1:51, 2:1-2\n",
    "print(getText(\"Genesis\", 1, 1, 1, 3)) # Genesis 1:1-3\n",
    "print(getText(\"Ephesians\", 5, 3))     # Ephesians 5:3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the function handles texts across multiple verses and chapters. It assumes no negative values or values too high (chapters and verses that don't exist).\n",
    "\n",
    "I also will need a simple helper function below to use df.apply later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextFromRawPBEData(r):\n",
    "  return getText(r['StartBook'], r['StartChapter'], r['StartVerse'], r['EndChapter'], r['EndVerse'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also need a function that creates a data frame ready for training. Define this function and explain how I know what my data needs to look like in the [Preprocessing Data](#preprocessing-data) section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Transfer Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format Research\n",
    "To know what format my data should take, I first try looking at the data format for other projects. I looked into the \"[Simplifying Paragraph-level Question Generation via Transformer Language Models](https://paperswithcode.com/paper/transformer-based-end-to-end-question)\" paper's hugging-face model as well as several T5 hugging-face packages for [Question Generation](https://huggingface.co/mrm8488/t5-base-finetuned-question-generation-ap). As shown in [`transferLearningResearch.ipynb`](transferLearningResearch.ipynb) the [Q&A Generation](https://huggingface.co/potsawee/t5-large-generation-squad-QuestionAnswer) model by potsawee is the best model currently.\n",
    "\n",
    "Here I load the model and its tokenizer and define a function for generating questions and answers to be used for comparison later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potsawee_T5 is a model taken from https://huggingface.co/potsawee/t5-large-generation-squad-QuestionAnswer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n",
    "\n",
    "def potsaweeAQG(text):\n",
    "  inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "  outputs = model.generate(**inputs, max_length=100)\n",
    "  question_answer = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "  question_answer = question_answer.replace(tokenizer.pad_token, \"\").replace(tokenizer.eos_token, \"\")\n",
    "  return question_answer.split(tokenizer.sep_token)\n",
    "\n",
    "def getPotsaweeModel():\n",
    "  return AutoModelForSeq2SeqLM.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I take a quick look at what the tokenizer does to the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And it was told the king of Jericho, saying, \"Behold, men have come here tonight from the children of Israel to search out the country.\"\n",
      "{'input_ids': [275, 34, 47, 1219, 8, 3, 1765, 13, 1022, 3723, 32, 6, 2145, 6, 96, 2703, 6134, 6, 1076, 43, 369, 270, 8988, 45, 8, 502, 13, 3352, 12, 960, 91, 8, 684, 535, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "joshua = nkjv[nkjv['Book'] == 'Joshua']\n",
    "joshua2 = joshua[joshua['ChapterNumber'] == 2]\n",
    "joshua2_2 = joshua2[joshua2[\"VerseNumber\"] == 2].iloc[0][\"Verse\"]\n",
    "print(joshua2_2)\n",
    "encoded_joshua2_2 = tokenizer(joshua2_2)\n",
    "print(encoded_joshua2_2)\n",
    "# print(json.dumps(encoded_joshua2_2, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And it was told the king of Jericho, saying, \"Behold, men have come here tonight from the children of Israel to search out the country.\"</s>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_joshua2_2[\"input_ids\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, when we tokenize an input verse, we have the data encoded in the format that the model expects. It auto-adds a separator after the sentence: `</s>`\n",
    "\n",
    "It also appears that the data needs to be converted into a format similar to Word2Vec to be processed by the model.\n",
    "\n",
    "Before we do data pre-processing, I we need to know what python types and structures are being used for the fine-tuning APIs. I'm going to try to format my data in the way the datasets library expects it in [this tutorial](https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6Ijk2OTcxODA4Nzk2ODI5YTk3MmU3OWE5ZDFhOWZmZjExY2Q2MWIxZTMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2ODE0MDU5MzEsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNTYyNTc2NjM3ODUwNzExNDYyMiIsImVtYWlsIjoibWFzaHVhMjQ2OEBnbWFpbC5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiYXpwIjoiMjE2Mjk2MDM1ODM0LWsxazZxZTA2MHMydHAyYTJqYW00bGpkY21zMDBzdHRnLmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tIiwibmFtZSI6Ik1hdG91xaEgSMO9YmwiLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUdObXl4WXpTcmVXdUVpbUt4R1NYNTZ6aVJKUVhZa0FjbzRZM3MwZ0VFeHFQUT1zOTYtYyIsImdpdmVuX25hbWUiOiJNYXRvdcWhIiwiZmFtaWx5X25hbWUiOiJIw71ibCIsImlhdCI6MTY4MTQwNjIzMSwiZXhwIjoxNjgxNDA5ODMxLCJqdGkiOiIxOWViNzFkNmFmY2EzNWZhMDdlYzRlOTNjMDRiYjgxODIxYzA1ZDZiIn0.WUmK7KYoJP6FCtwllBH0p84wCHSLficCTTcxKi7fmEbsHIoLHDXPbe9LNCD3kjWJ9gL1rLVNY9MmW_OJW7IjgavYp2C5xJs3a86T8bNfGkCDpScs9_6C5I-kzUz99tOWYitPob5ydmUsgkUwmDOldMf3SIrrhbV5DTBjcaLYJVCVcGng39e6b2OoIor08_iG6eMY030fTFb-R51RUI5TCfJOHEOLDjCglXMfDdtTGRSqzvTTC0kiIERCCpz1OY3Xb6nbBvACMCP5WRmiofoFpxBJHMB1y5_BaT5QZRPpuR2hbAHd1HJUMsrMAINbd2ToCvUsaOZrL2wBfOxA9YPLtA) which is where my sample data comes from. If I can get my data into that same format then I can be confident that the API will accept it.\n",
    "\n",
    "To run the following code, you need to get the `'medium-articles.zip'` file. After setting up a kaggle account and placing your `kaggle.json` in the proper place, run `kaggle datasets download -d fabiochiusano/medium-articles` in your terminal in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/mashu/.cache/huggingface/datasets/csv/default-d42b5ebe98124ded/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 662.50it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 110.50it/s]\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/mashu/.cache/huggingface/datasets/csv/default-d42b5ebe98124ded/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'text', 'url', 'authors', 'timestamp', 'tags'],\n",
      "        num_rows: 192368\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# look at an sample dataset to see what it looks like\n",
    "sample_data = load_dataset(\"csv\", data_files=\"medium-articles.zip\")\n",
    "print(sample_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Loading Function\n",
    "Looks like we have a DatasetDict format. Let's see if we can get our data to look the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Type', 'Question', 'Answer', 'NumberPoints', 'StartBook', 'StartChapter', 'StartVerse', 'EndBook', 'EndChapter', 'EndVerse'],\n",
      "        num_rows: 9983\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def getRawPBEData():\n",
    "  return pd.read_csv(PBEDataSource)\n",
    "pbe_data = getRawPBEData()\n",
    "pbe_data = Dataset.from_pandas(pbe_data)\n",
    "pbe_data = DatasetDict({\"train\": pbe_data})\n",
    "print(pbe_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Look at that. I think I have the data in the correct format now. Hopefully this will allow me to use the hugging-face training functions.\n",
    "\n",
    "##### Data Splitting Function\n",
    "At this point I will define a function that streamlines this data-loading from a dataframe and also splits the data up into a training, validation, and testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Type', 'Question', 'Answer', 'NumberPoints', 'StartBook', 'StartChapter', 'StartVerse', 'EndBook', 'EndChapter', 'EndVerse'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Type', 'Question', 'Answer', 'NumberPoints', 'StartBook', 'StartChapter', 'StartVerse', 'EndBook', 'EndChapter', 'EndVerse'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Type', 'Question', 'Answer', 'NumberPoints', 'StartBook', 'StartChapter', 'StartVerse', 'EndBook', 'EndChapter', 'EndVerse'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def dfToSplitDataDict(df):\n",
    "  # convert type\n",
    "  dataset = Dataset.from_pandas(df)\n",
    "  dataDict = DatasetDict({\"train\": dataset})\n",
    "  # split\n",
    "  train_test = dataDict[\"train\"].train_test_split(test_size=2000)\n",
    "  train_validation = train_test[\"train\"].train_test_split(test_size=1000)\n",
    "  dataDict[\"train\"] = train_validation[\"train\"]\n",
    "  dataDict[\"validation\"] = train_validation[\"test\"]\n",
    "  dataDict[\"test\"] = train_test[\"test\"]\n",
    "  \n",
    "  # shuffle\n",
    "  dataDict[\"train\"] = dataDict[\"train\"].shuffle().select(range(1000))\n",
    "  dataDict[\"validation\"] = dataDict[\"validation\"].shuffle().select(range(1000))\n",
    "  dataDict[\"test\"] = dataDict[\"test\"].shuffle().select(range(1000))\n",
    "\n",
    "  return dataDict\n",
    "\n",
    "# test function\n",
    "print(dfToSplitDataDict(getRawPBEData()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how in the function above I shuffle things. I do this for several reasons:\n",
    "* in case Tableau Prep Builder organized our data also, it is a good idea to shuffle \n",
    "* to separate out questions that are from different sources - some questions are from Babienco, Myaing, deFlutier, etc.\n",
    "* to ensure the question quality is about the same between training, validation, and testing data\n",
    "* make sure questions from different books are mixed up thoroughly - we don't want the model to remember context information from past questions, so feeding them in out of order might help that"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are about ready to pre-process. First I define a function that will generate `input_ids`, `attention_masks` and `labels` for each row. `input_ids` are the way the model/tokenizer keeps track of which words are which and `attention_masks` basically mark the important words. It seems to be an alternative to filtering stop words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring How To Preprocess Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "Model-specific settings are very important for fine-tuning. Since I am fine-tuning a pre-existing model, it is important that I feed it the proper sizes of input, the correct command, and the correctly-formatted labels. Many of these configurations are taken from the values specified in the [`original_config`](./original_config/) folder which contains configuration files for the potsawee T5 model.\n",
    "\n",
    "Notice the `command` variable. The command tells T5 what to do. The form of the command is minimal. Examples usually show commands such as `\"summarize:\"` or `\"translate to german:\"`. The command is not specified in the model's documentation. The [`config.json`](./original_config/config.json) file contains a `\"summarize:\"` prefix under the `task_specific_params` key, so that may be work trying out. Other wise something like `\"generate question and answer:\"` will be tested.\n",
    "\n",
    "`max_verse_length`, and `max_qa_length` variables specify how long the input and output can be, aka. the largest input size and output size. In this case I am using `512` for the maximum input size for verses because it appears several times in the configuration. Otherwise there are also max lengths of `200` and `300`. If training the model takes too long, decreasing this size may be useful. The output length, `max_qa_length`, is set at `128` as no value is provided in the config.\n",
    "\n",
    "##### Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command = \"generate question and answer: \"\n",
    "command = \"summarize: \"\n",
    "max_verse_length = 512\n",
    "max_qa_length = 128\n",
    "\n",
    "def tokenize(data):\n",
    "  inputs = [command + text for text in data[\"context\"]]\n",
    "  model_inputs = tokenizer(inputs, max_length=max_verse_length, truncation=True)\n",
    "\n",
    "  # Setup the potsawee_tokenizer for targets\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    qa = tokenizer(data[\"qa\"], max_length=max_qa_length, truncation=True)\n",
    "\n",
    "  model_inputs[\"labels\"] = qa[\"input_ids\"]\n",
    "  return model_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special Tokens\n",
    "One very interesting question is how the model is able to generate both a question and answer. All NLG pipelines generally produce a single stream of text as output, not two separate outputs.\n",
    "\n",
    "According to the [documentation online](https://huggingface.co/potsawee/t5-large-generation-squad-QuestionAnswer) the question and answer are output in the same string with the special added `<sep>` token separating the two (see [added_tokens.json](./original_config/added_tokens.json)). Thus, to continue training, this token must be inserted between the question and answer in \"labels.\"\n",
    "\n",
    "Documentation:\n",
    "* **Input**: context (e.g. news article)\n",
    "* **Output**: question `<sep>` answer\n",
    "\n",
    "##### Training Data Formatting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a dataframe passed to it in the PBE question format standardized\n",
    "# by https://pbeprep.com and turns it into the format that the model expects\n",
    "\n",
    "def qaCombine(r):\n",
    "  return r['Question'] + sep + r['Answer']\n",
    "\n",
    "def rawPBEToTrainingData(pbeData):\n",
    "  result = pd.DataFrame()\n",
    "  result[\"context\"] = pbeData.apply(getTextFromRawPBEData, axis=1)\n",
    "  result[\"qa\"] = pbeData.apply(qaCombine, axis=1)\n",
    "  return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the pieces in place let's test what our training data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>qa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Now it came to pass in the days of Ahasuerus (...</td>\n",
       "      <td>Which Ahasuerus is being spoken of in the book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in those days when King Ahasuerus sat on the t...</td>\n",
       "      <td>Where was King Ahasuerus' throne? (be specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in those days when King Ahasuerus sat on the t...</td>\n",
       "      <td>What was in Shushan the citadel? &lt;sep&gt; the thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in those days when King Ahasuerus sat on the t...</td>\n",
       "      <td>In what year of King Ahasuerus' reign did he m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in those days when King Ahasuerus sat on the t...</td>\n",
       "      <td>Where was the throne of his kingdom? &lt;sep&gt; in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Now it came to pass in the days of Ahasuerus (...   \n",
       "1  in those days when King Ahasuerus sat on the t...   \n",
       "2  in those days when King Ahasuerus sat on the t...   \n",
       "3  in those days when King Ahasuerus sat on the t...   \n",
       "4  in those days when King Ahasuerus sat on the t...   \n",
       "\n",
       "                                                  qa  \n",
       "0  Which Ahasuerus is being spoken of in the book...  \n",
       "1  Where was King Ahasuerus' throne? (be specific...  \n",
       "2  What was in Shushan the citadel? <sep> the thr...  \n",
       "3  In what year of King Ahasuerus' reign did he m...  \n",
       "4  Where was the throne of his kingdom? <sep> in ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbe_data = getRawPBEData()\n",
    "pbe_data = rawPBEToTrainingData(pbe_data)\n",
    "pbe_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like the format we want. Thus, we can finally push our data through all the preparation steps. Let's wrap this up into one, succinct function.\n",
    "##### Process Data Function\n",
    "1. Get data in PBE db format\n",
    "2. Make into the input and output format that we need.\n",
    "3. Split dataset\n",
    "4. Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData():\n",
    "  raw = getRawPBEData()\n",
    "  pbe_df = rawPBEToTrainingData(raw)\n",
    "  pbe_dict = dfToSplitDataDict(pbe_df)\n",
    "  pbe_tokens = pbe_dict.map(tokenize, batched=True)\n",
    "  return pbe_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training w/ Hugging Face"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbe_tokens = processData()\n",
    "print(pbe_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are ready to fine-tune the model. First we specify some hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model_location = './pbe_aqg_potsawee_t5'\n",
    "\n",
    "hyperparameters = Seq2SeqTrainingArguments(\n",
    "  model_location,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  eval_steps=100,\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=100,\n",
    "  save_strategy=\"steps\",\n",
    "  save_steps=200,\n",
    "  learning_rate=4e-5,\n",
    "  per_device_train_batch_size=batch_size,\n",
    "  per_device_eval_batch_size=batch_size,\n",
    "  weight_decay=0.01,\n",
    "  save_total_limit=3,\n",
    "  num_train_epochs=1,\n",
    "  predict_with_generate=True,\n",
    "  load_best_model_at_end=True,\n",
    "  metric_for_best_model=\"rouge1\",\n",
    "  report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an explanation for a few of the hyperparameters.\n",
    "* `model_location` is where the trained model will be stored\n",
    "* `evaluation_strategy` can be `\"no\"`, `\"steps\"`, or `\"epoch\"`. This determines whether the model is evaluated during training and how often\n",
    "* `eval_steps` tells the trainer to evaluate the model after every `100` steps. It is required when `evaluation_strategy` is`\"steps\"`\n",
    "* `logging_strategy`, `logging_steps`, `save_strategy`, and `save_steps` all follow the same format and function as `evaluation_strategy` and `eval_steps`\n",
    "* `learning_rate` the initial learning rate\n",
    "* `per_device_train_batch_size` and `per_device_eval_batch_size` refer to how large the batches are per each GPU/CPU\n",
    "* `weight_decay` is normal weight decay - see [explanation](https://vitalflux.com/weight-decay-in-machine-learning-concepts/#:~:text=Weight%20decay%20is%20a%20regularization%20technique%20that%20is%20used%20in,models%2C%20including%20deep%20neural%20networks.)\n",
    "* `num_train_epochs` specifies the number of epochs that should be performed by the trainer\n",
    "* `predict_with_generate` tells the trainer to evaluate the model while training\n",
    "* `metric_for_best_model` specifies the metric used to evaluate the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have a make a data collator with our tokenizer which will split up our data into batches and pad it appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set up our metric using the Hugging Face `evaluate` library.\n",
    "\n",
    "I borrow a metric computation function from [this tutorial](https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6Ijk2OTcxODA4Nzk2ODI5YTk3MmU3OWE5ZDFhOWZmZjExY2Q2MWIxZTMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2ODE0MDU5MzEsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNTYyNTc2NjM3ODUwNzExNDYyMiIsImVtYWlsIjoibWFzaHVhMjQ2OEBnbWFpbC5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiYXpwIjoiMjE2Mjk2MDM1ODM0LWsxazZxZTA2MHMydHAyYTJqYW00bGpkY21zMDBzdHRnLmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tIiwibmFtZSI6Ik1hdG91xaEgSMO9YmwiLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUdObXl4WXpTcmVXdUVpbUt4R1NYNTZ6aVJKUVhZa0FjbzRZM3MwZ0VFeHFQUT1zOTYtYyIsImdpdmVuX25hbWUiOiJNYXRvdcWhIiwiZmFtaWx5X25hbWUiOiJIw71ibCIsImlhdCI6MTY4MTQwNjIzMSwiZXhwIjoxNjgxNDA5ODMxLCJqdGkiOiIxOWViNzFkNmFmY2EzNWZhMDdlYzRlOTNjMDRiYjgxODIxYzA1ZDZiIn0.WUmK7KYoJP6FCtwllBH0p84wCHSLficCTTcxKi7fmEbsHIoLHDXPbe9LNCD3kjWJ9gL1rLVNY9MmW_OJW7IjgavYp2C5xJs3a86T8bNfGkCDpScs9_6C5I-kzUz99tOWYitPob5ydmUsgkUwmDOldMf3SIrrhbV5DTBjcaLYJVCVcGng39e6b2OoIor08_iG6eMY030fTFb-R51RUI5TCfJOHEOLDjCglXMfDdtTGRSqzvTTC0kiIERCCpz1OY3Xb6nbBvACMCP5WRmiofoFpxBJHMB1y5_BaT5QZRPpuR2hbAHd1HJUMsrMAINbd2ToCvUsaOZrL2wBfOxA9YPLtA). It:\n",
    "1. decodes prediction tokens into words\n",
    "2. decodes labels after padding\n",
    "3. computes ROUGE scores using the decoded predictions and labels\n",
    "4. computes a new metric, which is the average length of the predictions\n",
    "5. returns a dictionary of metrics\n",
    "\n",
    "This custom metrics function is a good place to tweak what we want the output to look like. Possibly, we will want to insentivize different outputs as we get better models trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# compute takes a tuple of (predictions, labels)\n",
    "def compute_metrics(eval_pred):\n",
    "  predictions, labels = eval_pred\n",
    "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "  \n",
    "  # replace -100 in the labels as we can't decode them.\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  \n",
    "  # rouge expects a newline after each sentence\n",
    "  decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "  decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "  \n",
    "  # compute ROUGE scores\n",
    "  result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "  # extract ROUGE f1 scores\n",
    "  result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "  \n",
    "  # add mean generated length to metrics\n",
    "  prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "  result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "  \n",
    "  return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before training, we need to configure the trainer and point it to our data and pretrained model.\n",
    "\n",
    "We pass in a model initialization function `getPotsaweeModel` so that the trainer will always start with our base model rather than anything else whe may have done training on. We also pass in all the `hyperparameters` that we set up earlier.\n",
    "\n",
    "Also notice that we pass in our tokenized PBE data for training and validation.\n",
    "\n",
    "Finally, we give it the potsawee `tokenizer` and our own `compute_metrics` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "  model_init=getPotsaweeModel,\n",
    "  args=hyperparameters,\n",
    "  train_dataset=pbe_tokens[\"train\"],\n",
    "  eval_dataset=pbe_tokens[\"validation\"],\n",
    "  data_collator=data_collator,\n",
    "  tokenizer=tokenizer,\n",
    "  compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm still in the process of getting a TensorBoard to work. When I do, we will get to see the training in progress. The board will display in the notebook right below its launching code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir './pbe_aqg_potsawee_t5/runs'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
